[{"paper_title": "Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents", "paper_summary": "The paper proposes a fully decentralized framework for multi\u2011agent reinforcement learning (MARL) where agents are located on a time\u2011varying communication network and each agent only knows its own reward function. Each agent selects actions based on local observations and messages received from its neighbors, and the collective objective is to maximize the average return over the network. Two actor\u2011critic algorithms are introduced: actors are computed independently by each agent, while critics are updated through a consensus mechanism across the network. Convergence guarantees are proved when value functions are approximated with linear functions, and the authors show empirical results using both linear and nonlinear function approximators. This work is the first to combine fully decentralized MARL, networked agents, and function approximation while providing provable convergence. The algorithms are fully incremental and can be run online, making them suitable for large\u2011scale distributed systems. Extensive simulations demonstrate that the methods outperform naive baselines and scale efficiently as the number of agents increases.", "relevance": "The ability to coordinate agents without a central server is crucial for distributed applications such as IoT, robotic swarms, and large\u2011scale resource allocation. By proving convergence under function approximation, the paper provides a solid theoretical foundation for practical deployment of decentralized MARL systems. Future work could extend the framework to deep neural network approximators, asynchronous communication, and dynamic task environments, further broadening its applicability. The approach also opens avenues for studying robustness against communication delays, packet loss, and malicious agents.", "related_topics": ["decentralized reinforcement learning", "consensus\u2011based learning", "actor\u2011critic algorithms"], "url": "https://arxiv.org/abs/1802.08757"}]