[{"paper_title": "CITB: A Benchmark for Continual Instruction Tuning", "paper_summary": "The paper introduces CITB, a benchmark designed to study how large language models can be continually fine\u2011tuned on instruction\u2011based tasks without forgetting prior knowledge. It defines a new problem setting called Continual Instruction Tuning (CIT), where models receive a stream of natural language instructions paired with dialogue data. Two long dialogue streams, InstrDialog and InstrDialog++, are curated to provide diverse, realistic instruction sequences for evaluation. Experiments show that standard continual learning methods struggle to exploit the richness of these instructions; surprisingly, simply fine\u2011tuning an instruction\u2011tuned model sequentially often matches or outperforms specialized CL approaches. The authors also investigate factors that influence CIT performance, such as instruction style and task ordering, highlighting open challenges for future research. By releasing the benchmark and data, the paper offers the community a standardized protocol for developing and testing lifelong learning techniques on instruction\u2011driven dialogue tasks.", "relevance": "CITB addresses a critical gap at the intersection of continual learning and instruction tuning, two hot topics in NLP. By providing a concrete, reproducible benchmark, it encourages researchers to design algorithms that can adapt to new instructions while preserving past knowledge, a key requirement for real\u2011world conversational agents. The finding that simple sequential fine\u2011tuning can be competitive suggests that instruction\u2011rich pre\u2011training may already encode useful transfer mechanisms, guiding future work toward hybrid or more efficient lifelong learning strategies. Overall, the benchmark opens avenues for exploring lifelong dialogue systems, instruction generalization, and continual knowledge integration in large language models.", "related_topics": ["Continual Learning", "Instruction Tuning", "Dialogue Systems"], "url": "https://arxiv.org/abs/2310.14510"}]