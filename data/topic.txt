Dynamic multiâ€‘objective pretraining for large language models